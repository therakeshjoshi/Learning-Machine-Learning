{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70193242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b604b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/workspaces/Learning-Machine-Learning/Datasets/Social_Network_Ads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae3be823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4993ff57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>41</td>\n",
       "      <td>87000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>24</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>26</td>\n",
       "      <td>86000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>36</td>\n",
       "      <td>126000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>48</td>\n",
       "      <td>29000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  EstimatedSalary  Purchased\n",
       "378   41            87000          1\n",
       "178   24            23000          0\n",
       "108   26            86000          0\n",
       "226   36           126000          1\n",
       "19    48            29000          1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3850abcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('Purchased', axis =1), df['Purchased'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17e6378e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((280, 4), (120, 4))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a6c495",
   "metadata": {},
   "source": [
    "### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96362f8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Male'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_9572/1827734602.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m sklearn.preprocessing \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m      2\u001b[39m scaler = StandardScaler()\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# fit the scaler to the train set, it will learn the parameters\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m scaler.fit(X_train) \u001b[38;5;66;03m#means mean and sd wala prcudure\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#transform train and test sets\u001b[39;00m\n\u001b[32m      7\u001b[39m X_train_scaled = scaler.transform(X_train)\n",
      "\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/preprocessing/_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    920\u001b[39m             Fitted scaler.\n\u001b[32m    921\u001b[39m         \"\"\"\n\u001b[32m    922\u001b[39m         \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    923\u001b[39m         self._reset()\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.partial_fit(X, y, sample_weight)\n",
      "\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1332\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m                 )\n\u001b[32m   1335\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/preprocessing/_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    957\u001b[39m             Fitted scaler.\n\u001b[32m    958\u001b[39m         \"\"\"\n\u001b[32m    959\u001b[39m         xp, _, X_device = get_namespace_and_device(X)\n\u001b[32m    960\u001b[39m         first_call = \u001b[38;5;28;01mnot\u001b[39;00m hasattr(self, \u001b[33m\"n_samples_seen_\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m         X = validate_data(\n\u001b[32m    962\u001b[39m             self,\n\u001b[32m    963\u001b[39m             X,\n\u001b[32m    964\u001b[39m             accept_sparse=(\u001b[33m\"csr\"\u001b[39m, \u001b[33m\"csc\"\u001b[39m),\n",
      "\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2898\u001b[39m             out = y\n\u001b[32m   2899\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2900\u001b[39m             out = X, y\n\u001b[32m   2901\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2902\u001b[39m         out = check_array(X, input_name=\u001b[33m\"X\"\u001b[39m, **check_params)\n\u001b[32m   2903\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2904\u001b[39m         out = _check_y(y, **check_params)\n\u001b[32m   2905\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1019\u001b[39m                         )\n\u001b[32m   1020\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1021\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1022\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1024\u001b[39m                 raise ValueError(\n\u001b[32m   1025\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1026\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/sklearn/utils/_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    874\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    875\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    876\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    877\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    879\u001b[39m \n\u001b[32m    880\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2167\u001b[39m             )\n\u001b[32m   2168\u001b[39m         values = self._values\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2171\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2172\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2173\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2174\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Male'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# fit the scaler to the train set, it will learn the parameters\n",
    "scaler.fit(X_train) #means mean and sd wala prcudure\n",
    "\n",
    "#transform train and test sets\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.mean_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
